{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QovT45u4cpGF"
   },
   "source": [
    "# Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объедини общие данные о фильмах [tmdb_5000_movies](https://files.sberdisk.ru/s/te4QbzdxKgsFQXA) и каст фильмов \n",
    "[tmdb_5000_credits](https://files.sberdisk.ru/s/H9oRuXQt5mFz3T9). Оставь в датасете только фильмы, которые вышли в \"релиз\".\\\n",
    "Выведи количество фильмов, оставшихся после фильтрации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество фильмов после фильтрации: 4795\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Загрузка данных из CSV файлов\n",
    "credits_df = pd.read_csv('../datasets/tmdb_5000_credits.csv')\n",
    "movies_df = pd.read_csv('../datasets/tmdb_5000_movies.csv')\n",
    "\n",
    "# Переименование колонки \"movie_id\" в \"id\" для последующего объединения\n",
    "credits_df.rename(columns={'movie_id': 'id'}, inplace=True)\n",
    "\n",
    "# Объединение данных по колонке \"id\"\n",
    "merged_df = pd.merge(movies_df, credits_df, on='id')\n",
    "\n",
    "# Фильтрация фильмов, которые вышли в \"релиз\"\n",
    "filtered_df = merged_df[merged_df['status'] == 'Released']\n",
    "\n",
    "# Вывод количества фильмов после фильтрации\n",
    "num_movies_remaining = len(filtered_df)\n",
    "print(\"Количество фильмов после фильтрации:\", num_movies_remaining)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый наивный подход к рекомендации фильмов - рекомендовать фильмы с лучшими оценками пользователей. Фильмы, которые пользуются большей популярностью и признанием критиков, с большей вероятностью понравятся среднему зрителю."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для справедливой оценки фильмов возьмем текущую рейтинговую систему IMDB (weighted rating (WR)), которая рассчитывается по формуле:\n",
    "$$WR = \\frac{v}{v + m} ⋅ R + \\frac{m}{v + m} ⋅ C$$ \n",
    "$v$ - количество голосов \\\n",
    "$m$ - количество голосов для включения в финальную таблицу \\\n",
    "$R$ - средняя оценка \\\n",
    "$C$ - средняя оценка всех фильмов \n",
    "\n",
    "Имплементируй функцию `weighted_rating`. С её помощью расcчитай рейтинг для каждого фильма и сохрани его в колонку `simple_score`.\\\n",
    "Выведи топ-5 фильмов по получившемуся рейтингу.\n",
    "> В качестве параметра $m$ выбери 95-й квантиль количества голосов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_rating(v, m, R, C):\n",
    "    x = (v / (v + m)) * R + (m / (v + m)) * C\n",
    "    return  x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                original_title  vote_count  vote_average  simple_score\n",
      "1881  The Shawshank Redemption        8205           8.5      7.849025\n",
      "65             The Dark Knight       12002           8.2      7.773990\n",
      "662                 Fight Club        9413           8.3      7.761012\n",
      "96                   Inception       13752           8.1      7.736496\n",
      "3232              Pulp Fiction        8428           8.3      7.714726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/indexing.py:1667: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Расчет 95-го квантиля количества голосов (m)\n",
    "m = filtered_df['vote_count'].quantile(0.95)\n",
    "\n",
    "# Средняя оценка всех фильмов (C)\n",
    "C = filtered_df['vote_average'].mean()\n",
    "\n",
    "# Расчет рейтинга для каждого фильма\n",
    "filtered_df.loc[:, 'simple_score'] = filtered_df.apply(lambda row: weighted_rating(row['vote_count'], m, row['vote_average'], C), axis=1)\n",
    "\n",
    "# Вывод топ-5 фильмов по рейтингу (взвешенному рейтингу)\n",
    "top_5_movies = filtered_df.sort_values('simple_score', ascending=False).head(5)\n",
    "\n",
    "print(top_5_movies[['original_title', 'vote_count', 'vote_average', 'simple_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой подход к рекомендациям очень наивен, так как не учитывает информацию о самом фильме (жанр, режиссер, описание, актеры и т.п). \\\n",
    "**Content Based Filtering** (Фильтрация на основе содержания) - тип рекомендательной системы, которая предлагает пользователям похожие элементы на основе конкретного элемента. Общая идея этих рекомендательных систем заключается в том, что если человеку понравился определенный товар, то ему понравится и похожий на него товар."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"../misc/images/content.png\" alt= “” width=\"300\" height=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем алгоритм рекомендации на основе описания фильма. Для это требуется провести предобработку текста:\n",
    "* Замени NaN в описании фильма на пустой символ `''`\n",
    "* Удали все английские стоп слова (используй параметр `stop_words` в `TfidfVectorizer`)\n",
    "* Расcчитай [Tf-Idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) для описания фильма\n",
    "\n",
    "Выведи размер получившейся матрицы Tf-Idf\n",
    "\n",
    "> Для [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) используйте параметры по умолчанию "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы Tf-Idf: (4795, 20970)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "# Замена NaN в описании фильма на пустой символ ''\n",
    "filtered_df.loc[:, 'overview'] = filtered_df['overview'].fillna('')\n",
    "\n",
    "# Удаление английских стоп слов\n",
    "stop_words = list(text.ENGLISH_STOP_WORDS)\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words)\n",
    "\n",
    "# Расчет Tf-Idf для описания фильма\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(filtered_df['overview'])\n",
    "\n",
    "# Вывод размера получившейся матрицы Tf-Idf\n",
    "print(\"Размер матрицы Tf-Idf:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь тебе необходимо вычислить показатель сходства между описаниями фильмов. Используем косинусное расстояние, оно рассчитывается по формуле:\n",
    "$$cos(Θ) = \\frac{A ⋅ B}{∥A∥ ∥B∥} = \\frac{ Σ_{i=1}^{n} A_i ⋅ B_i } { \\sqrt{Σ_{i=1}^{n}A_{i}^{2}} ⋅ {\\sqrt{Σ_{i=1}^{n}B_{i}^{2}}}}$$\n",
    "Но поскольку мы использовали векторизатор TF-IDF на предыдущем шаге, достаточно вычислить скалярное произведение, которое и даст оценку косинусного сходства. Рассчитать его можно через [linear_kernel](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.linear_kernel.html). Результат сохрани в переменную `cosine_sim`.\n",
    "\n",
    "Выведи размер получившейся матрицы `cosine_sim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы cosine_sim: (4795, 4795)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Рассчитываем косинусное сходство между описаниями фильмов\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Вывод размера получившейся матрицы cosine_sim\n",
    "print(\"Размер матрицы cosine_sim:\", cosine_sim.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напиши функцию `get_recommendations`. На вход она принимает:\n",
    "* `movies_dataset` - датасет фильмов\n",
    "* `title` - название фильма, для которого мы будем искать похожие\n",
    "* `cosine_sim` - матрица расстояний между описаниями\n",
    "* `top_k` - топ-k cхожих фильмов\n",
    "\n",
    "Возвращает top_k названий фильмов, описание которых похоже на выбранный фильм.\\\n",
    "Выведи топ-5 фильмов для `title='Saving Private Ryan'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(movies_dataset, title, cosine_sim, top_k=10):\n",
    "    # Получаем индекс фильма по его названию\n",
    "    idx = movies_dataset[movies_dataset['original_title'] == title].index[0]\n",
    "\n",
    "    # Получаем показатели сходства для фильма с выбранным индексом\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Сортируем фильмы по показателям сходства в убывающем порядке\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Индексы топ-K фильмов с наибольшими показателями сходства\n",
    "    top_indices = [i[0] for i in sim_scores[1:top_k+1]]\n",
    "\n",
    "    # Возвращаем топ-K названий фильмов\n",
    "    return movies_dataset['original_title'].iloc[top_indices] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "787         The Great Raid\n",
      "586      The Monuments Men\n",
      "290      The Expendables 2\n",
      "4168             Abandoned\n",
      "3516             The Train\n",
      "1525        Apocalypse Now\n",
      "2430             Evil Dead\n",
      "3603     Lone Wolf McQuade\n",
      "3586    As Above, So Below\n",
      "755     Star Trek: Nemesis\n",
      "Name: original_title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "recommendations = get_recommendations(movies_dataset=filtered_df, title='Saving Private Ryan', cosine_sim=cosine_sim)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один подход к построению рекомендательной системы - подход на основе сходства между пользователями. Этот подход называется **Collaborative Filtering** (Коллаборативная фильтрация).\n",
    "<center><img src=\"../misc/images/all.png\" alt= “” width=\"600\" height=\"700\"></center>\n",
    "Коллаборативная фильтрация - это тип рекомендательной системы, которая использует поведение и предпочтения похожих пользователей для рекомендации товаров или продуктов конкретному пользователю. Система собирает данные о прошлом поведении пользователей, такие как покупки, рейтинги и отзывы, и анализирует их для выявления закономерностей и сходства между пользователями. На основе этих закономерностей система рекомендует товары, которые понравились или были приобретены другими такими же пользователями в прошлом.\n",
    "\n",
    "Для реализации Коллаборативной фильтрации нам потребуются оценки пользователей [ratings](../datasets/ratings.csv).\n",
    "\n",
    ">userId - id пользователя \\\n",
    "movieId - id фильма \\\n",
    "rating - оценка фильма (от 0 до 5)\\\n",
    "timestamp - время оценки\n",
    "\n",
    "\n",
    "Воспользуйся библиотекой [surprise](https://surpriselib.com/) для обучения модели оценки рейтинга фильма [SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD). Выведи средние значения 'RMSE', 'MAE' на кросс-валидации с параметрами `cv=5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9073  0.8876  0.8985  0.8955  0.8997  0.8977  0.0064  \n",
      "MAE (testset)     0.6973  0.6852  0.6902  0.6914  0.6933  0.6915  0.0039  \n",
      "Fit time          0.73    0.71    0.71    0.70    0.70    0.71    0.01    \n",
      "Test time         0.07    0.06    0.11    0.06    0.11    0.08    0.02    \n",
      "Среднее RMSE на кросс-валидации: 0.8977438494228908\n",
      "Среднее MAE на кросс-валидации: 0.6914625715693313\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.prediction_algorithms.matrix_factorization import SVD\n",
    "\n",
    "# Загрузка данных оценок пользователей из файла 'ratings.csv'\n",
    "ratings = pd.read_csv('../datasets/ratings.csv')\n",
    "\n",
    "# Загружаем данные оценок пользователей\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# Создаем модель SVD\n",
    "svd_model = SVD()\n",
    "\n",
    "# Выполняем кросс-валидацию с параметрами cv=5\n",
    "results = cross_validate(svd_model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
    "\n",
    "# Выводим средние значения RMSE и MAE\n",
    "print(\"Среднее RMSE на кросс-валидации:\", results['test_rmse'].mean())\n",
    "print(\"Среднее MAE на кросс-валидации:\", results['test_mae'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
